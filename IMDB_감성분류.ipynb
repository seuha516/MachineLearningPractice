{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB 감성분류",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO2T3HZJopCCZUg457Dv3dX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seuha516/practice-machine-learning/blob/main/IMDB_%EA%B0%90%EC%84%B1%EB%B6%84%EB%A5%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "(train_input, train_target), (test_input, test_target) = imdb.load_data(num_words = 1000)"
      ],
      "metadata": {
        "id": "J6kZ58KuqKmt"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_input, val_input, train_target, val_target = train_test_split(train_input, train_target, test_size = 0.2, stratify = train_target, random_state = 36)"
      ],
      "metadata": {
        "id": "JCcCyeNhJhXf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "train_seq = pad_sequences(train_input, maxlen = 200)\n",
        "val_seq = pad_sequences(val_input, maxlen = 200)"
      ],
      "metadata": {
        "id": "gHpomgFYLTka"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(1000, 64, input_length = 200))\n",
        "model.add(keras.layers.LSTM(8, dropout = 0.3, return_sequences = True))\n",
        "model.add(keras.layers.LSTM(8, dropout = 0.3))\n",
        "model.add(keras.layers.Dense(1, activation = 'sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "K61Yw5EDN9X8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmsprop=keras.optimizers.RMSprop(learning_rate = 1e-4)\n",
        "model.compile(optimizer = rmsprop, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint('best-model.h5')\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 3, restore_best_weights = True)\n",
        "history = model.fit(train_seq, train_target, epochs = 100, batch_size = 64,\n",
        "                    validation_data = (val_seq, val_target),\n",
        "                    callbacks = [checkpoint_cb, early_stopping_cb])"
      ],
      "metadata": {
        "id": "T_xoyIl2TcZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "rnn_model = keras.models.load_model('best-model.h5')\n",
        "positive_input = []\n",
        "positive_target = np.array([1] * 12500)\n",
        "negative_input = []\n",
        "negative_target = np.array([0] * 12500)\n",
        "\n",
        "for i in range(25000):\n",
        "  if test_target[i] == 1:\n",
        "    positive_input.append(test_input[i])\n",
        "  else:\n",
        "    negative_input.append(test_input[i])\n",
        "\n",
        "test_seq = pad_sequences(test_input, maxlen = 200)\n",
        "positive_seq = pad_sequences(positive_input, maxlen = 200)\n",
        "negative_seq = pad_sequences(negative_input, maxlen = 200)\n",
        "positive_input=np.array(positive_input)\n",
        "negative_input=np.array(negative_input)\n",
        "\n",
        "print(\"=== 성능 평가 ===\")\n",
        "print(\"전체 테스트\")\n",
        "rnn_model.evaluate(test_seq, test_target)\n",
        "print(\"긍정 문장 테스트\")\n",
        "rnn_model.evaluate(positive_seq, positive_target)\n",
        "print(\"부정 문장 테스트\")\n",
        "rnn_model.evaluate(negative_seq, negative_target)"
      ],
      "metadata": {
        "id": "NO0k52slnD1x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e856a78-eccf-471f-fa76-1dac70c872c9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== 성능 평가 ===\n",
            "전체 테스트\n",
            "782/782 [==============================] - 23s 28ms/step - loss: 0.3436 - accuracy: 0.8540\n",
            "긍정 문장 테스트\n",
            "391/391 [==============================] - 10s 26ms/step - loss: 0.3879 - accuracy: 0.8272\n",
            "부정 문장 테스트\n",
            "391/391 [==============================] - 10s 26ms/step - loss: 0.2993 - accuracy: 0.8808\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2992817461490631, 0.8808000087738037]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "word_to_index = imdb.get_word_index()\n",
        "def predict(sentence):\n",
        "  print(sentence)\n",
        "  sentence = re.sub('[^0-9a-zA-Z ]', '', sentence).lower()\n",
        "  encoded = []\n",
        "  for x in sentence.split():\n",
        "    try :\n",
        "      if word_to_index[x] <= 1000:\n",
        "        encoded.append(word_to_index[x] + 3)\n",
        "      else:\n",
        "        encoded.append(2)\n",
        "    except KeyError:\n",
        "      encoded.append(2)\n",
        "  data = pad_sequences([encoded], maxlen = 200)\n",
        "  score = float(rnn_model.predict(data))\n",
        "  if(score > 0.5):\n",
        "    print(\"{:.3f}% 확률로 긍정\\n\".format(score * 100))\n",
        "  else:\n",
        "    print(\"{:.3f}% 확률로 부정\\n\".format((1 - score) * 100))\n",
        "\n",
        "test_sentences = [\n",
        "                  \"Terrible plot and script, boring and pointless\",\n",
        "                  \"Dr Stupid in the Mashed Potatoes\",\n",
        "                  \"This is why we go to the movies\",\n",
        "                  \"Tom Cruise really knows how a blockbuster film is made.\",\n",
        "                  \"Either I am growing older Or MCU is becoming more Childish\",\n",
        "                  \"Watched it twice and will watch it again and again\",\n",
        "                  \"I thought I was watching a Thor parody.\",\n",
        "                  \"Can't remember the last time I smiled so much in the cinema!\",\n",
        "\n",
        "                  \"I love this movie. It's wonderful!\",\n",
        "                  \"I lov this movie. It's wonderfull!\",\n",
        "                  \"One of the worst superhero movies out there\",\n",
        "                  \"One of the wrost superhero movies out there\",\n",
        "                  \"A perfect storm\",\n",
        "                  \"Frankly, I think this is a wild goose chase.\",\n",
        "                  \"I don't know why everyone hates this movie.\"\n",
        "                  ]\n",
        "\n",
        "for sentence in test_sentences:\n",
        "  predict(sentence)"
      ],
      "metadata": {
        "id": "Pb6Nop8nkDP0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f84f3db9-a0ee-4c07-a4ce-97e7d193dd3a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Terrible plot and script, boring and pointless\n",
            "92.702% 확률로 부정\n",
            "\n",
            "Dr Stupid in the Mashed Potatoes\n",
            "83.318% 확률로 부정\n",
            "\n",
            "This is why we go to the movies\n",
            "60.113% 확률로 부정\n",
            "\n",
            "Tom Cruise really knows how a blockbuster film is made.\n",
            "67.803% 확률로 긍정\n",
            "\n",
            "Either I am growing older Or MCU is becoming more Childish\n",
            "67.356% 확률로 부정\n",
            "\n",
            "Watched it twice and will watch it again and again\n",
            "71.477% 확률로 긍정\n",
            "\n",
            "I thought I was watching a Thor parody.\n",
            "51.389% 확률로 부정\n",
            "\n",
            "Can't remember the last time I smiled so much in the cinema!\n",
            "63.911% 확률로 긍정\n",
            "\n",
            "I love this movie. It's wonderful!\n",
            "70.926% 확률로 긍정\n",
            "\n",
            "I lov this movie. It's wonderfull!\n",
            "55.801% 확률로 부정\n",
            "\n",
            "One of the worst superhero movies out there\n",
            "89.323% 확률로 부정\n",
            "\n",
            "One of the wrost superhero movies out there\n",
            "51.870% 확률로 부정\n",
            "\n",
            "A perfect storm\n",
            "65.659% 확률로 긍정\n",
            "\n",
            "Frankly, I think this is a wild goose chase.\n",
            "51.089% 확률로 긍정\n",
            "\n",
            "I don't know why everyone hates this movie.\n",
            "50.949% 확률로 긍정\n",
            "\n"
          ]
        }
      ]
    }
  ]
}